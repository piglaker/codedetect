{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import csv\n",
    "\n",
    "\n",
    "def get_data(path):\n",
    "    data=[]\n",
    "\n",
    "    with open(path) as fd:\n",
    "        rd=csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for line in rd:\n",
    "            li=line[-1]\n",
    "            data.append(li)\n",
    "                        \n",
    "    return data\n",
    "\n",
    "d = get_data(\"./eng/nature/CoLA/dev.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The sailors rode the breeze clear of the rocks.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_QNLI_data(i):\n",
    "        data=[]\n",
    "        with open(\"./eng/nature/QQP/\" + i + \".tsv\") as fd:\n",
    "            rd=csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "            for i, line in enumerate(rd):\n",
    "                if i == 0:\n",
    "                    continue\n",
    "                data.append(line[-2])\n",
    "                data.append(line[-3])         \n",
    "        return data\n",
    "\n",
    "d = get_QNLI_data(\"dev\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Why are hispanics so beautiful?'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from asyncore import read\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from typing import Dict, List\n",
    "import itertools\n",
    "\n",
    "from tqdm import tqdm\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    MBart50TokenizerFast,\n",
    ")\n",
    "import jieba\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"/remote-home/xtzhang/playground/tmp/codedetect/\")\n",
    "\n",
    "from utils.io import read_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_dir = \"./data/eng/nature\"\n",
    "\n",
    "code_dir = \"./data/eng/code\"\n",
    "\n",
    "\n",
    "def load_json(data_path):\n",
    "    \n",
    "    file = open(data_path, 'r', encoding='utf-8')\n",
    "\n",
    "    data = []\n",
    "\n",
    "    for line in file.readlines():\n",
    "        tmp = json.loads(line)\n",
    "        data.extend( tmp[\"original_string\"].split(\"\\n\") )   \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0x93 in position 35: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xd7 in position 400: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x85 in position 929: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x97 in position 55: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xed in position 17: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "head=\"/remote-home/xtzhang/playground/tmp/codedetect/data/eng/code\"\n",
    "dirs = os.listdir(head + \"/c\")\n",
    "all_c = []\n",
    "for d in dirs:\n",
    "    tmp = read_csv(head + \"/c/\" + d)\n",
    "    if tmp:\n",
    "        all_c.extend(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_code(head=\"/remote-home/xtzhang/playground/tmp/codedetect/data/eng/code\"):\n",
    "    #dirs = os.listdir( nature_dir )\n",
    "    types = [ \"train\", \"valid\", \"test\" ]\n",
    "    program_names = [ \"python\", \"go\", \"php\", \"java\", \"javascript\", ]\n",
    "    \n",
    "    code_data = { i:[] for i in types }\n",
    "    trunc_table = {\"train\":12000, \"valid\":1500, \"test\":1500}\n",
    "\n",
    "    for program_name in program_names:\n",
    "        for i in types:\n",
    "            path = \"_\".join([program_name, i, \"0\"]) + '.jsonl'\n",
    "            tmp = load_json( head + \"/\" +path )\n",
    "            #print(len(tmp))\n",
    "            \n",
    "            code_data[i].extend(tmp[:trunc_table[i]])\n",
    "    \n",
    "    dirs = os.listdir(head + \"/c\")\n",
    "    all_c = []\n",
    "    for d in dirs:\n",
    "        tmp = read_csv(head + \"/c/\" + d)\n",
    "        if tmp:\n",
    "            all_c.extend(tmp)\n",
    "\n",
    "    import random\n",
    "    random.shuffle(all_c)\n",
    "    \n",
    "    code_data[\"train\"].extend(all_c[:12000])\n",
    "    code_data[\"valid\"].extend(all_c[12000:13500]) \n",
    "    code_data[\"test\"].extend(all_c[13500:])\n",
    "    \n",
    "    return code_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'utf-8' codec can't decode byte 0x93 in position 35: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xd7 in position 400: invalid continuation byte\n",
      "'utf-8' codec can't decode byte 0x85 in position 929: invalid start byte\n",
      "'utf-8' codec can't decode byte 0x97 in position 55: invalid start byte\n",
      "'utf-8' codec can't decode byte 0xed in position 17: invalid continuation byte\n"
     ]
    }
   ],
   "source": [
    "code_data = read_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72000\n",
      "9000\n",
      "9721\n"
     ]
    }
   ],
   "source": [
    "for values in code_data.values():\n",
    "    print(len(values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_nature(head=\"/remote-home/xtzhang/playground/tmp/codedetect/data/eng/nature\"):\n",
    "    #dirs = os.listdir( nature_dir )\n",
    "    types = [ \"train\", \"dev\", \"test\" ]\n",
    "    dataset_names = [ \"CoLA\", \"QNLI\", \"QQP\", \"STS-B\", \"WNLI\", ]\n",
    "    \n",
    "    nature_data = { i:[] for i in types }\n",
    "    trunc_table = {\"train\":12000, \"dev\":1500, \"test\":1500}\n",
    "\n",
    "    for name in dataset_names:\n",
    "        for i in types:\n",
    "            path = name + \"/\" + i + \".tsv\"\n",
    "            tmp = read_csv( head + \"/\" +path )\n",
    "            #print(len(tmp))\n",
    "            \n",
    "            nature_data[i].extend(tmp[:trunc_table[i]])\n",
    "    \n",
    "\n",
    "    return nature_data\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "nature_data = read_nature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38937\n",
      "5615\n",
      "5591\n"
     ]
    }
   ],
   "source": [
    "for values in nature_data.values():\n",
    "    print(len(values))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "117",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7e2dc701bf398b464ce69644f23ea143adca83783263e47d39149d5b90225121"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
